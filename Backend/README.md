# ğŸ“° AI News Chatbot Backend

This backend powers a **retrieval-augmented AI chatbot** that answers user queries using real news articles.  
It integrates **Groq LLM**, **Qdrant vector database**, and **transformer embeddings** to provide context-aware responses.

---

## ğŸš€ Features

- **Context-aware AI** â€“ Generates responses using both conversation history and retrieved news sources.
- **Semantic Search** â€“ Uses embeddings to find relevant news articles in Qdrant.
- **Session Management** â€“ Persists user conversations in JSON for multi-turn chat.
- **Automatic Ingestion** â€“ Fetches and processes articles into embeddings automatically.
- **Flexible Configuration** â€“ Environment variables control API keys, model selection, and storage paths.

---

## ğŸ›  Technology Stack

### Backend
- **Node.js** â€“ High-performance, event-driven JavaScript runtime.
- **Express.js** â€“ Lightweight framework for building REST APIs.
- **CORS** â€“ Handles cross-origin requests securely.

### Vector Database
- **Qdrant** â€“ Stores embeddings of news articles for fast semantic retrieval.

### Embeddings
- **@xenova/transformers** â€“ Converts text to numerical vectors for semantic search.

### Language Model
- **Groq SDK** â€“ Accesses LLM models (e.g., `llama-3.3-70b-versatile`) for generating AI responses.

### News Source
- **Scraped Articles** â€“ Local JSON storage of scraped news articles.

### Session Management
- **JSON Storage** â€“ Stores user sessions and conversation history.
- **Auto Session Handling** â€“ Creates and persists new sessions automatically.

---

## âš™ï¸ Environment Variables

Create a `.env` file in the root directory:

```bash
# Server
PORT=4000

# Groq AI LLM
GROQ_API_KEY=your_groq_api_key
GROQ_MODEL=llama-3.3-70b-versatile

# Qdrant vector database
QDRANT_URL=your_qdrant_url
QDRANT_API_KEY=your_qdrant_api_key

# Data directory for articles and sessions
DATA_DIR=./data
